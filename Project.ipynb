{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "train=pd.read_csv('C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Data\\\\train.csv',sep=',')\n",
    "test=pd.read_csv('C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Data\\\\test.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PHash Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.DataFrame(test['posting_id'])\n",
    "sub['phash']=[' '.join(list(test.loc[test.image_phash==test.iloc[i].image_phash].posting_id)) for i in range(len(test))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF with KNN - 21 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from nltk.corpus import stopwords\n",
    "import string\n",
    "words=(train['title'].append(test['title'])).str.lower().str.translate(str.maketrans('','',string.punctuation)).str.split().explode().value_counts()\n",
    "words=list(set(words[words>1].index.values.tolist()))#-set(stopwords.words('english')))\n",
    "tfidf=TfidfVectorizer(use_idf=True,vocabulary=words)\n",
    "X_train=pd.DataFrame(tfidf.fit_transform(train['title']).toarray(),columns=tfidf.get_feature_names())\n",
    "y_train=train['label_group']\n",
    "X_test=pd.DataFrame(tfidf.fit_transform(test['title']).toarray(),columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn=KNeighborsClassifier(n_neighbors=21)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.DataFrame(test['posting_id'])\n",
    "temp['pred']=y_pred\n",
    "sub['tfidf']=temp['pred'].map(temp.groupby('pred').posting_id.agg('unique')) #matching posting id against predicted labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del words,tfidf,TfidfVectorizer,string,X_train,y_train,X_test,knn,KNeighborsClassifier,y_pred,temp\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split [80-20] #common code used with image and text as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_train,y_train,test_size=0.2,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Preprocessing and stored in Matrix (64 x 64 grayscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_pre(img):\n",
    "    return np.ndarray.flatten(cv2.GaussianBlur(cv2.resize(img,(64,64)),(15,15),0)) \n",
    "\n",
    "from os.path import join\n",
    "import cv2\n",
    "trvec=[]\n",
    "lab=[]\n",
    "for i in train[['image','label_group']].drop_duplicates().iterrows():\n",
    "    trvec.append(img_pre(cv2.imread(join('C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Data\\\\train_images',i[1][0]),0)))\n",
    "    lab.append(i[1][1])\n",
    "trvec=pd.DataFrame(trvec)\n",
    "lab=pd.DataFrame(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trvec.to_csv(path_or_buf='C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Gen\\\\training_image_vector.csv',header=None,index=False,index_label=None,mode='w')\n",
    "lab.to_csv(path_or_buf='C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Gen\\\\training_image_label.csv',header=None,index=False,index_label=None,mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trvec=pd.read_csv('C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Gen\\\\training_image_vector.csv',sep=',',header=None)\n",
    "lab=pd.read_csv('C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Gen\\\\training_image_label.csv',sep=',',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from os.path import join\n",
    "tsvec=pd.DataFrame([np.ndarray.flatten(cv2.GaussianBlur(cv2.resize(cv2.imread(join('C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Data\\\\test_images',j),0),(64,64)),(15,15),0)) for j in test['image']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder as LE\n",
    "y=pd.DataFrame(LE().fit_transform(lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trvec/=255 #normalize data\n",
    "tsvec/=255\n",
    "\n",
    "from sklearn.decomposition import PCA #reduce dimensionality\n",
    "pca=PCA(0.95)#n_components=50)\n",
    "pca.fit(trvec)\n",
    "train_img=pca.transform(trvec)\n",
    "test_img=pca.transform(tsvec)\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "X_train=LDA(n_components=2).fit_transform(trvec,lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(n_estimators=100)\n",
    "y_pred_rf=rf.fit(train_img,lab).predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model=XGBClassifier(use_label_encoder=True)\n",
    "y_pred_xgb=model.fit(train_img,lab).predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_des=[]\n",
    "descr=[]\n",
    "orb = cv2.ORB_create()\n",
    "for i in train['image']:\n",
    "    im=cv2.resize(cv2.imread(join('C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Data\\\\train_images',i)),(128,128))\n",
    "    key,des=orb.detectAndCompute(im,None)\n",
    "    tr_des.append(des)\n",
    "for j in test['image']:\n",
    "    im=cv2.resize(cv2.imread(join('C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Data\\\\test_images',j)),(128,128))\n",
    "    key,des=orb.detectAndCompute(im,None)\n",
    "    descr.append(des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del orb,im,key,des\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu',input_shape=(64,64,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(len(np.unique(lab)),activation='softmax')])\n",
    "cnn.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(np.reshape(np.asarray(trvec),(32460,64,64,1)),y,epochs=10)\n",
    "y_pred=cnn.predict(np.asarray(tsvec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Preprocessing and stored in Matrix (128 x 128 BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#128x128 rgb images trial\n",
    "trvec=[]\n",
    "lab=[]\n",
    "for i in train[['image','label_group']].drop_duplicates().iterrows():\n",
    "    trvec.append(cv2.resize(cv2.imread(join('C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Data\\\\train_images',i[1][0])),(128,128)))\n",
    "    lab.append(i[1][1])\n",
    "#trvec=pd.DataFrame(trvec)\n",
    "lab=pd.DataFrame(lab)\n",
    "tsvec=[cv2.resize(cv2.imread(join('C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Data\\\\test_images',j)),(128,128)) for j in test['image']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trvec.to_csv(path_or_buf='C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Gen\\\\training_image_vector.csv',header=None,index=False,index_label=None,mode='w')\n",
    "lab.to_csv(path_or_buf='C:\\\\Users\\\\Pratik\\\\Desktop\\\\Assignments\\\\CS584\\\\Project\\\\Gen\\\\training_image_label.csv',header=None,index=False,index_label=None,mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "ann=models.Sequential([layers.Flatten(input_shape=(128,128,3)),\n",
    "        layers.Dense(3000, activation='relu'),\n",
    "        layers.Dense(1000, activation='relu'),\n",
    "        layers.Dense(11014, activation='sigmoid')])\n",
    "ann.compile(optimizer='SGD',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "ann.fit(np.asarray(trvec),y,epochs=10)\n",
    "y_pred=ann.predict(np.asarray(tsvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu',input_shape=(128,128,3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64,activation='relu'),\n",
    "    layers.Dense(len(np.unique(lab)),activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(np.asarray(trvec),y,epochs=5)\n",
    "y_pred=cnn.predict(np.asarray(tsvec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm=pd.DataFrame(test['posting_id'])\n",
    "subm['pred']=y_pred\n",
    "subm['matches']=subm.groupby('pred')['posting_id'].head(50)\n",
    "subm=subm.drop(columns='pred')\n",
    "subm.to_csv(path_or_buf='C:\\\\Users\\\\Pratik\\\\Desktop\\\\submission.csv',index=False,index_label=None,mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pending\n",
    "sub['matches']=#(1.phash) (2. image) (3. tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=sub.drop(columns=['phash','tfidf'])\n",
    "sub.to_csv(path_or_buf='C:\\\\Users\\\\Pratik\\\\Desktop\\\\submission.csv',index=False,index_label=None,mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
